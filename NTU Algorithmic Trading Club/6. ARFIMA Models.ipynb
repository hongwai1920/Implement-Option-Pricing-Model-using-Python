{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: Prado's Advances in Financial Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quandl\n",
    "import statsmodels.tsa.stattools as st\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "#plotting libraries\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Initialize figure size (in inches)\n",
    "plt.rcParams['figure.figsize'] = [10,5]\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsplot(y, lags=None, title='', figsize=(14, 8)):\n",
    "    '''Examine the patterns of ACF and PACF, along with the time series plot and histogram.\n",
    "    \n",
    "    Original source: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax   = plt.subplot2grid(layout, (0, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (0, 1))\n",
    "    acf_ax  = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    \n",
    "    y.plot(ax=ts_ax)\n",
    "    ts_ax.set_title(title)\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "    [ax.set_xlim(0) for ax in [acf_ax, pacf_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return ts_ax, acf_ax, pacf_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf(series):\n",
    "    adf_result = st.adfuller(series, store = True)\n",
    "    print(\"ADF Test Results: \")\n",
    "    print(\"Test Statistic: %.4f\" % adf_result[0])\n",
    "    print(\"p-value: %.10f\" % adf_result[1])\n",
    "    print(\"Critical Values: \")\n",
    "    for key, value in adf_result[2].items():\n",
    "        print('\\t%s: %0.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss(series):\n",
    "    kpss_result = st.kpss(series, store=True)\n",
    "    print(\"KPSS Test Results: \")\n",
    "    print(\"Test Statistic: %.4f\" % kpss_result[0])\n",
    "    print(\"p-value: %.10f\" % kpss_result[1])\n",
    "    print(\"Critical Values: \")\n",
    "    for key, value in kpss_result[2].items():\n",
    "        print('\\t%s: %0.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TSLA from quandl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Quandl unifies financial and economic datasets from hundreds of publishers on a single user-friendly platform.\n",
    "\n",
    "* Most datasets on Quandl are available directly in Python, using the Quandl Python module.\n",
    "\n",
    "* The Quandl Python package is free to use and grants access to all free datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set API key (saved locally on machine)\n",
    "quandl.ApiConfig.api_key = os.environ.get('quandl_api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you are not familiar with quandl database and its functions, try using dir and help functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(quandl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# documentation of quandl.get\n",
    "help(quandl.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us extract the stock Tesla (TSLA) from quandl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla = quandl.get('WIKI/TSLA')\n",
    "tsla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that all descriptive statistics of Open, High, Low, Close and Volume are the same as Adj. Open, Adj. High, Adj. Low, Adj. Close and Adj. Volume respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(tsla['High'], title = 'Tesla High Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ACF and PACF of Tesla resemble AR(2) model. This might suggest that fitting ARMA$(2,0)$ is a good guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract close price values to get numpy array of values\n",
    "price_list = tsla['Adj. Close'].values\n",
    "\n",
    "#shift price list by one down and replace first entry with na value\n",
    "shifted_prices = np.roll(price_list, shift=1, axis=0)\n",
    "shifted_prices[:1] = np.nan\n",
    "\n",
    "#calculate returns numpy array\n",
    "tsla_returns = ((price_list - shifted_prices)/shifted_prices)*100\n",
    "\n",
    "#plot graph of returns below\n",
    "plt.ylabel(\"% change\")\n",
    "plt.yticks(np.arange(-20,21,2))\n",
    "plt.ylim(-22,22)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.title(\"TSLA Returns\")\n",
    "plt.tight_layout()\n",
    "plt.plot(tsla.index, tsla_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation of Fractional Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Returns are stationary but memoryless while price series have memory but non-stationary.\n",
    "\n",
    "* $\\textbf{Integer differencing wipe out all memories.}$\n",
    "\n",
    "* There is a trade-off between stationarity and memory.\n",
    "\n",
    "Recall that $L$ is the lag operator.\n",
    "For a real number $d,$ we have \n",
    "\n",
    "$$\\begin{align*}\n",
    "(1-L)^d & = \\sum_{k=0}^\\infty \\binom{d}{k} (-L)^k \\\\\n",
    "& = 1 - dL + \\frac{d(d-1)}{2!} L^2 - \\frac{d(d-1)(d-2)}{3!} L^3 + \\dots\n",
    "\\end{align*}$$\n",
    "\n",
    "The arithmetic series consists of \n",
    "\n",
    "$$\\tilde{X}_t = \\sum_{k=0}^\\infty \\omega_k X_{t-k}$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\\omega = \\left\\{1 ,-d, \\frac{d(d-1)}{2!}, -\\frac{d(d-1)(d-2)}{3!}, \\dots,(-1)^k \\prod_{i=0}^{k-1} \\frac{(d-i)}{k!},\\dots \\right\\}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$X = {X_t, X_{t-1}, X_{t-2},..., X_{t-k},...}$$\n",
    "\n",
    "If $d$ is an integer, then \n",
    "\n",
    "$$\\prod_{i=0}^{k-1} \\frac{(d-i)}{k!} = 0 \\quad \\text{for all } k>d.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractional Differencing Part 1: Finding weights & Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For $k\\geq 1,$ if $w_0 = 1,$ the weights can be generated iteratively as:\n",
    "\n",
    "$$w_k = - w_{k-1} \\frac{d-k+1}{k}.$$\n",
    "\n",
    "* The following findWeights_FFD and fracDiff functions are similar to functions Snippet 5.1 (page $79$) and Snippet 5.2 (page $82$) in Prado's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Computes the weights for our fractionally differenced features up to a given threshold\n",
    "   requirement for fixed-window fractional differencing. \n",
    "    Args:\n",
    "        d: A float representing the differencing factor\n",
    "        length: An int length of series to be differenced\n",
    "        threshold: A float representing the minimum threshold to include weights for\n",
    "    Returns:\n",
    "        A numpy array containing the weights to be applied to our time series\n",
    "\"\"\"\n",
    "def findWeights_FFD(d, length, threshold):\n",
    "    #set first weight to be 1 and k to be 1\n",
    "    w, k = [1.], 1\n",
    "    w_curr = 1\n",
    "    \n",
    "    #while we still have more weights to process, do the following:\n",
    "    while(k < length):\n",
    "        \n",
    "        w_curr = (-w[-1]*(d-k+1))/k\n",
    "        \n",
    "        #if the current weight is below threshold, exit loop\n",
    "        if(abs(w_curr) <= threshold):\n",
    "            \n",
    "            break\n",
    "            \n",
    "        #append coefficient to list if it passes above threshold condition\n",
    "        w.append(w_curr)\n",
    "        \n",
    "        #increment k\n",
    "        k += 1\n",
    "        \n",
    "    #make sure to convert it into a numpy array and reshape from a single row to a single\n",
    "    #column so they can be applied to time-series values easier\n",
    "    w = np.array(w[::-1]).reshape(-1,1)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Computes fractionally differenced series \n",
    "    Args:\n",
    "        d: A float representing the differencing factor (any positive fractional)\n",
    "        series: A pandas dataframe with one or more columns of time-series values to be differenced\n",
    "        threshold: Threshold value past which we ignore weights \n",
    "            (cutoff weight for window)\n",
    "    Returns: \n",
    "        diff_series: A numpy array of differenced series by d. \n",
    "\"\"\"\n",
    "def fracDiff(series, d, threshold = 1e-5):\n",
    "    #compute weights using function above\n",
    "    weights = findWeights_FFD(d, len(series), threshold)\n",
    "    width = len(weights) - 1\n",
    "    \n",
    "    df = {}\n",
    "    #for each series to be differenced, apply weights to appropriate prices and save \n",
    "    for name in series.columns:\n",
    "        \n",
    "        #forward fill through unavailable prices and create a temporary series to hold values\n",
    "        curr_series = series[[name]].fillna(method='ffill').dropna()\n",
    "        df_temp = pd.Series()\n",
    "        \n",
    "        #loop through all values that fall into range to be fractionally differenced\n",
    "        for iloc1 in range(width, curr_series.shape[0]):\n",
    "            \n",
    "            #set values for first and last time-series point to be used in current pass of fractional\n",
    "                #difference\n",
    "            loc0 = curr_series.index[iloc1-width]\n",
    "            loc1 = curr_series.index[iloc1]\n",
    "            \n",
    "            #make sure current value is valid\n",
    "            if not np.isfinite(curr_series.loc[loc1,name]):\n",
    "                continue\n",
    "            \n",
    "            #dot product of weights with values from first and last indices\n",
    "            df_temp[loc1]= np.dot(weights.T, curr_series.loc[loc0:loc1])[0,0]\n",
    "            \n",
    "        df[name] = df_temp.copy(deep=True)\n",
    "    df = pd.concat(df, axis=1)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractional Differencing Part 2: Test-Run/Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series = tsla[['Adj. Close']]\n",
    "df_result = fracDiff(test_series, 0.5, 1e-5)\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Differenced Prices', color=color)\n",
    "ax1.plot(df_result.index, df_result['Adj. Close'], color=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Prices', color = color)\n",
    "ax2.plot(df_result.index, tsla['Adj. Close'].values[-(df_result.shape[0]):], color=color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ADF and KPSS Tests for stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\textbf{ADF Test}$: This test is used to detect the presence of a unit-root.\n",
    "\n",
    "2. $\\textbf{KPSS Test}$: This test is used to detect the presence of trend-stationarity around a deterministic trend.\n",
    "\n",
    "\n",
    "* These two tests are meant to complement each other. By testing both the unit-root and trend-stationarity, it gives us a better idea of where we can categorize the stochastic behaviour of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the adf test and displaying results\n",
    "adf(df_result['Adj. Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is definitely a good thing since such a low p-value is basically telling us there is no unit root (and hence no non-stationary trend in our data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the kpss test and displaying results\n",
    "kpss(df_result['Adj. Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although at least 10% doesn't sound like a whole lot, it definitely is in statistics. This test also further shows that our series is in-fact very likely to be trend-stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying Starting Conditions: How do test results fare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you curious on how our test results change as our differencing parameter changes? So, below, let us look at how changing our threshold value (for fractional differencing coefficients) and differencing factors change the results of the adf test results.\n",
    "\n",
    "I also decide to take a look at how these parameters change the number of data points we are able to difference (or the length of the differenced series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please wait for at least 5 minutes for the cell to run completely\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "#the 130 combinations to test, varying values of our thresholds and differencing factors\n",
    "thresh_values = [1e-3, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 9e-5, 7e-5, 5e-5, 3e-5]\n",
    "diff_values = [0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2]\n",
    "\n",
    "#dataframe to hold results\n",
    "pval_hyperparam_df = pd.DataFrame(0.1, columns = thresh_values, index=diff_values)\n",
    "\n",
    "#dataframe to hold lengths \n",
    "lengths_df = pd.DataFrame(1, columns = thresh_values, index = diff_values)\n",
    "\n",
    "#to keep track of column and row indices when placing results in dataframe\n",
    "col = 0\n",
    "row = 0\n",
    "\n",
    "#cycle through each combination of threshold values and diff values\n",
    "    # and generate adf test-statistics for each combination\n",
    "    \n",
    "for i in thresh_values:\n",
    "    for j in diff_values:\n",
    "        \n",
    "        #fractionally difference series and store series lengths\n",
    "        test_diff_series = fracDiff(test_series, j, i)\n",
    "        lengths_df.iat[row,col] = test_diff_series.shape[0]\n",
    "        \n",
    "        #run and collect adf fuller test\n",
    "        test_adf_result = st.adfuller(test_diff_series['Adj. Close'], regression = 'ctt', store = True)\n",
    "        \n",
    "        pval_hyperparam_df.iat[row, col] = test_adf_result[0]\n",
    "        \n",
    "        row += 1\n",
    "    row = 0\n",
    "    col += 1\n",
    "    \n",
    "#display our results\n",
    "(pval_hyperparam_df)\n",
    "display(lengths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Heatmap plot just so we get a better idea of how these changes are happening\n",
    "heatmap = sns.heatmap(pval_hyperparam_df, vmin=0, vmax=-12, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that higher amounts of differencing do typically lead to much more negative test-statistics (which translate to very low p-values). All in all, this basically tells us that as we increase our differencing factor our series becomes more stationary. This would make sense since we typically take first differences (d=1) to get returns which are considered stationary.\n",
    "\n",
    "What this chart highlights is the fact that we don't actually have to overly difference a series to get trend-stationarity in the underlying series.\n",
    "\n",
    "Also notice that lowering our threshold, holding the differencing-factor constant, lowers the number of observations we can difference (and this is much more pronounced for lower differencing factors since the values converge much quicker). The same can be said for holding our threshold constant and decreasing our differencing factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitfalls, Limitations, Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, why do we need to be careful about what we've been studying here? Well, for the ADF test in particular, testing for a unit-root and testing for trend-stationarity aren't exactly the same thing. The weird thing is, it is possible for a time series to be non-stationary but have no unit root.\n",
    "\n",
    "Trend-stationary tests (like the KPSS test) are really looking for time-series convergence around a certain mean, and this mean can grow or shrink over time. Unit root processes however, assume that shocks to our series have a permanent impact.\n",
    "\n",
    "Also, in the presence of time-varying variance (which is the case in some of the computed examples above), our results becomes less robust (although this can be easily fixed by conducting other unit root tests such as the Phillips-Peron test that is more robust to heteroskedasticity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what exactly has this series of posts shown? Virtually all finance papers apply integer differencing (a factor of 1) and is usually overkill for most financial time-series. This over-differencing causes most if not all memory to be lost, leaving us very little with regard to information in using prices in statistical models.\n",
    "\n",
    "I'll conclude with a thought that radically shifted my perspective on quantitative trading:\n",
    "\n",
    "It's important to think about quantitative trading from a statistical framework. The price path you see in a chart is simply a realized price path, generated from an underlying distribution (that we, unfortunately, don't know much about). Going forward, under repeated sampling, we have to assume that other price paths are also very likely.\n",
    "\n",
    "Thinking about equity curves and time-series paths in this manner definitely make things more confusing but solidify why statistical ideas, although complex on the surface, are so useful and powerful in giving quants an edge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
