{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import gauss\n",
    "from random import seed\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "#import pandas_profiling\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsplot(y, \n",
    "           lags=None, \n",
    "           title='', \n",
    "           figsize=(14, 8)):\n",
    "    '''Examine the patterns of ACF and PACF, along with the time series plot and histogram.\n",
    "    \n",
    "    Original source: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax   = plt.subplot2grid(layout, (0, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (0, 1))\n",
    "    acf_ax  = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    \n",
    "    y.plot(ax=ts_ax)\n",
    "    ts_ax.set_title(title)\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "    [ax.set_xlim(0) for ax in [acf_ax, pacf_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return ts_ax, acf_ax, pacf_ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic and Stochastic Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Deterministic process** does not involve randomness in the development of future states of the system. Therefore, it will always produce the same output from a given starting condition or initial state.\n",
    "\n",
    "* **Stochastic process / random process** is a collection of random variables $\\{X_t\\}_{t\\in T}$ indexed by a set $T$. In time series, $T$ often represents either $\\mathbb{N}$ or $\\mathbb{R}_{\\geq 0}$. It differs from deterministic process as it involves randomness.\n",
    "\n",
    "* **Mean** and **variance**  of a stochastic process are functions $M:T\\to \\mathbb{R}$ and $V:T\\to \\mathbb{R}_{\\geq 0}$ defined by \n",
    "\n",
    "$$M(t) = E(X_t) \\quad \\text{and} \\quad V(t) = Var(X_t).$$\n",
    "\n",
    "* For instance, we could consider a process $\\{ð‘‹_n\\}_{n\\in\\mathbb{N}}$ in discrete time, where $ð‘‹_n \\sim N(\\mu_n,\\sigma^2_n)$ for some $\\mu_ð‘›,\\sigma_n\\in \\mathbb{N}$ with $\\sigma_ð‘›>0$. In this case we simply get\n",
    "\n",
    "$$ M(n)=\\mu_n \\quad \\text{and}\\quad V(n)=\\sigma_n^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocovariance, autocorrelation and partial autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suppose that $\\{X_t\\}_t$ is a stochastic process.\n",
    "\n",
    "* The $\\textbf{autocovariance function}$ is defined as\n",
    "\n",
    "$$\\gamma(s,t) = cov(X_s,X_t) = E[(X_s-\\mu_s)(X_t-\\mu_t)] \\quad \\text{for all } s,t.$$\n",
    "\n",
    "* Two natural implications are \n",
    "\n",
    "$$(1) \\quad \\gamma(s,t) = \\gamma(t,s) \\quad\\text{and}\\quad (2) \\quad\\gamma(s,s) = cov(X_s,X_s) = E[(X_s-\\mu_s)^2]$$\n",
    "\n",
    "* A correlation of a variable with itself at different times is known as $\\textbf{autocorrelation}$. If a time series model is second-order stationary (i.e. stationary in both mean and variance: $\\mu_t = \\mu$ and $\\sigma_t^2 = \\sigma^2$ for all $t$), then an $\\textit{autocovariance function}$ can be expressed as a function only of the time lag $k$:\n",
    "\n",
    "$$ \\gamma(k) = E[(X_t-\\mu)(X_{t+k} - \\mu)] $$\n",
    "  \n",
    "* Likewise, the autocorrelation function $\\textit{acf}$ is defined as\n",
    "\n",
    "$$ \\rho(k) = \\frac{\\gamma(k)}{\\gamma(0)} $$\n",
    "  \n",
    "* When $k=0$, $\\rho(0) = 1$\n",
    "\n",
    "* The $\\textbf{partial autocorrelation}$ provide a relationship between two variables after removing third variable. Informally, the partial correlation between $X_t$ and $X_{t+h}$ is the autocorrelation between $X_t$ and $X_{t+h}$ without the contribution of $X_{t+1},X_{t+2},....,X_{t+k-1}.$\n",
    "\n",
    "* Mathematically, it is defined as \n",
    "\n",
    "$$\\phi_{kk} = Corr( X_t - P(X_t| X_{t+1},...,X_{t+k-1}), X_{t+k} - P(X_t| X_{t+1},...,X_{t+k-1})  )$$\n",
    "\n",
    "where $P(W|Z)$ is the 'best linear projection' of $W$ on $Z$, that is, $P(W|Z) = Cov(W,Z) Var(Z)^{-1} Z.$\n",
    "The 'best linear projection' is understood in the sense of minimizing the mean squared error.\n",
    "\n",
    "* For more information on acf and pacf, please consult [Time Series Analysis by James Douglas Hamilton](https://www.amazon.com/Time-Analysis-James-Douglas-Hamilton/dp/0691042896)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* White noise is the basic building block for most time series due to the Wold's decomposition theorem.\n",
    "\n",
    "* White noise is a collection $\\{\\epsilon_t\\}_t$ of random variables whose mean is 0 and autocovariance function satisfying\n",
    "\n",
    "$$\\gamma(h) = \\begin{cases} \n",
    "      \\sigma^2 & \\text{ if } h = 0 \\\\\n",
    "      0 & \\text{ if } h \\neq 0\n",
    "   \\end{cases} .$$\n",
    "   \n",
    "* White noise may not follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed(1)\n",
    "\n",
    "# create white noise series\n",
    "series = [gauss(0.0, 1.0) for i in range(1000)]\n",
    "series = pd.Series(series)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary stats\n",
    "series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the mean is and standard deviation are slightly different from what we assign.\n",
    "The following is a plot of the generate white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* White noise above exhibits random behavior but follows normal distribution. \n",
    "\n",
    "* Observe that autocorrelation and partial correlation of white noise are closed to 0.\n",
    "\n",
    "* The following generates numbers using random number generators.  We want to verify whether the collection is a white noise or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.Series([random.randint(1,100) for i in range(1000)])\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "numbers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From its autocorrelation and partial autocorrelation, it seems that random numbers generated above indeed a white noise.\n",
    "\n",
    "* White noise is useful when looking at residual plot of forecasting models to determine whether they use all available information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268.667px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
