{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.tsa.stattools as st\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsplot(y, lags=None, title='', figsize=(14, 8)):\n",
    "    '''Examine the patterns of ACF and PACF, along with the time series plot and histogram.\n",
    "    \n",
    "    Original source: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax   = plt.subplot2grid(layout, (0, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (0, 1))\n",
    "    acf_ax  = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    \n",
    "    y.plot(ax=ts_ax)\n",
    "    ts_ax.set_title(title)\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "    [ax.set_xlim(0) for ax in [acf_ax, pacf_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return ts_ax, acf_ax, pacf_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA_plot_ki(series, \n",
    "               order,\n",
    "               train_size_percent,\n",
    "               scale=1):\n",
    "    \n",
    "    # Credit to Fong King Ian for providing this code\n",
    "\n",
    "    # convert Series to DataFrame\n",
    "    # remove duplicated rows except for most recent, convert to daily freq, fil blanks with prev observation\n",
    "    X = series.rename(\"actual\").to_frame() \n",
    "    X = X.loc[~X.index.duplicated(keep='last')].asfreq('d', 'ffill')\n",
    "    \n",
    "    # determine where the training set ends and the test set starts\n",
    "    size = int(len(X) * train_size_percent)\n",
    "    first_test_index = X.index[size]\n",
    "        \n",
    "    # forecast out-of-sample value using ARIMA\n",
    "    for t in X[X.index >= first_test_index].index.tolist():\n",
    "        # fit model with 'actual' values up to and excluding time t\n",
    "        model = ARIMA(X[X.index < t]['actual'].values, order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        \n",
    "        # forecast returns 3 arrays: \n",
    "        # out-of-sample forecast value, std error of the forecast and \n",
    "        # 2d array of the confidence interval for the forecast \n",
    "        \n",
    "        output = model_fit.forecast()\n",
    "        X.loc[t, 'predictions'] = output[0]  # output[0] contains forecast value\n",
    "#        print('predicted = %f, expected = %f' % (output[0], X.at[t, 'actual']))\n",
    "    \n",
    "    # aligning predictions with correct time periods, removing rows without predictions\n",
    "    X['predictions'] = X['predictions'].shift(-1)\n",
    "    X.dropna(inplace = True)\n",
    "    \n",
    "    # MSE\n",
    "    error = mean_squared_error(X['actual'].values, X['predictions'].values)\n",
    "    print('Test MSE: %.3f' % error)\n",
    "    \n",
    "    # Scale to avoid exceeding maximum margin of plots\n",
    "    test_scaled = X['actual'].values / scale\n",
    "    predictions_scaled = X['predictions'].values / scale\n",
    "\n",
    "    # plot\n",
    "    plt.plot(test_scaled, color='blue', label='true values')\n",
    "    plt.plot(predictions_scaled, color='red', label=f'estimated ARIMA{order}')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA_plot(series, \n",
    "               order,\n",
    "               train_size_percent,\n",
    "               scale = 1):\n",
    "    \n",
    "    # Split data points into train and test sets\n",
    "    X = series\n",
    "    size = int(len(X) * train_size_percent)\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "    history = list(train)\n",
    "    predictions = []\n",
    "    \n",
    "    # Forecast out-of-sample value using ARIMA\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order)     \n",
    "        model_fit = model.fit(disp=0)\n",
    "        # forecast returns 3 arrays: \n",
    "        # out-of-sample forecast value, std error of the forecast and \n",
    "        # 2d array of the confidence interval for the forecast \n",
    "        output = model_fit.forecast()\n",
    "        # yhat contains forecast value\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    \n",
    "    # MSE\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    print('Test MSE: %.3f' % error)\n",
    "    \n",
    "    # Scale to avoid exceeding maximum margin of plots\n",
    "    test_scaled = [x/scale for x in test]\n",
    "    predictions_scaled = [x/scale for x in predictions]\n",
    "\n",
    "    # plot\n",
    "    plt.plot(test_scaled, color = 'blue', label = 'true values')\n",
    "    plt.plot(predictions_scaled, color='red', label = 'estimated ARIMA{}'.format(order))\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ARIMA(series, order):\n",
    "    model = ARIMA(series, order)\n",
    "    model_fit = model.fit(disp=0)\n",
    "    return model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIC_BIC_HIQC(series, max_ar = 4, max_ma= 4):\n",
    "    train_results = sm.tsa.arma_order_select_ic(series, ic=['aic', 'bic', 'hqic'], trend='nc', max_ar=max_ar, max_ma=max_ma)\n",
    "\n",
    "    print('AIC', train_results.aic_min_order)\n",
    "    print('BIC', train_results.bic_min_order)\n",
    "    print('HQIC', train_results.hqic_min_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf(series):\n",
    "    adf_result = st.adfuller(series, store = True)\n",
    "    print(\"ADF Test Results: \")\n",
    "    print(\"Test Statistic: %.4f\" % adf_result[0])\n",
    "    print(\"p-value: %.10f\" % adf_result[1])\n",
    "    print(\"Critical Values: \")\n",
    "    for key, value in adf_result[2].items():\n",
    "        print('\\t%s: %0.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss(series):\n",
    "    kpss_result = st.kpss(series, store=True)\n",
    "    print(\"KPSS Test Results: \")\n",
    "    print(\"Test Statistic: %.4f\" % kpss_result[0])\n",
    "    print(\"p-value: %.10f\" % kpss_result[1])\n",
    "    print(\"Critical Values: \")\n",
    "    for key, value in kpss_result[2].items():\n",
    "        print('\\t%s: %0.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Sets and Differencing Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Bitcoin's and Amazon's historical price in yahoo Finance as csv file\n",
    "BitCoin = read_csv('BTC-USD.csv', \n",
    "                               header = 0, \n",
    "                               parse_dates = [0],  \n",
    "                               index_col = 0, \n",
    "                               squeeze = True, \n",
    "                               date_parser = parser)\n",
    "\n",
    "Amazon = read_csv('amzn.csv',  \n",
    "                  header = 0, \n",
    "                  parse_dates = [0],\n",
    "                  index_col = 0,\n",
    "                  squeeze = True,\n",
    "                 date_parser = parser)\n",
    "\n",
    "AAPL_df = read_csv('AAPL.csv',\n",
    "                  header = 0, \n",
    "                  parse_dates = [0],  \n",
    "                  index_col = 0, \n",
    "                  squeeze = True, \n",
    "                  date_parser = parser)\n",
    "\n",
    "temp_df = read_csv('daily-minimum-temperatures.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BitCoin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BitCoin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BitCoin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(BitCoin['High'], title = 'Bitcoin High Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not all time series are stationary. In fact, most financial time series lack of stationarity.\n",
    "\n",
    "* One method to 'stationarize' non-stationary time series is through differencing\n",
    "\n",
    "* Notation: $\\nabla = 1 - L$ where $L$ is the lag operator\n",
    "\n",
    "* Advantage of differencing: \n",
    "\n",
    "    (1) No parameter estimation is required  \n",
    "\n",
    "    (2) Can be repeated such that first difference $\\nabla$ eliminates a linear trend whereas second difference $\\nabla^2$ eliminates a quadratic trend\n",
    "\n",
    "* Order of differencing $d$: $\\nabla^d = (1-L)^d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference Bitcoin high price by one interval\n",
    "Bitcoin_high_diff = difference(BitCoin['High'], 2)\n",
    "tsplot(Bitcoin_high_diff, title = 'Difference BitCoin High Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the differenced Bitcoin High price series stationary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf(Bitcoin_high_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test statistics is less than all critical values. So according to ADF test, we can reject null hypothesis and conclude that the difference series is indeed stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(BitCoin['Low'], title = 'Bitcoin Open Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference Bitcoin low price by one interval\n",
    "Bitcoin_low_diff = difference(BitCoin['Low'], 1)\n",
    "tsplot(Bitcoin_low_diff, title = 'Difference Bitcoin Low Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adf(Bitcoin_low_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Again, the test statistics is less than all critical values. So we reject null hypothesis and conclude that the difference series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(temp_df['Temp'], title = 'Temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference temperature by one interval\n",
    "temp_df_diff = difference(temp_df['Temp'])\n",
    "tsplot(temp_df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf(temp_df_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test statistics is less than all critical values. So the difference series is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA$(p,d,q)$ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A time series $\\{X_t\\}$ follows an ARIMA$(p,d,q)$ process if the $d^{th}$ differences $(1-L)^d X_t$ series is an ARMA($p,q$) process. Using lag operator $L$, it can expressed as \n",
    "\n",
    "$$\\begin{equation}\n",
    "  \\phi(L)(1-L)^d X_t = c + \\theta(L) \\epsilon_t\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\phi(L) = 1 - \\phi_1 L - \\phi_2 L^2 - ... - \\phi_p L^p$ and $\\theta_q = 1 + \\theta_1 L + \\theta_2 L^2 - ... + \\theta_q L^q.$\n",
    "\n",
    "* In Python, $d=0,1,2.$ Higher value of $d$ is not accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Jenkins Method (ARIMA Model Identification)\n",
    "\n",
    "* To estimate the parameters of a specific ARIMA$(p, d, q)$ model:\n",
    "\n",
    "* To check on the appropriateness of the fitted model and improve it if needed.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "1. **Model identification and model selection:** Determine the *order of differencing*, $d$\n",
    "\n",
    "2. **Parameter estimation:** Study the ACF and PACF of the appropriately differenced series: $(1-L)^d X_t$, as these autocorrelation functions will provide indication for the choice of the order of autoregressive and the moving average components.  It is very beneficial to study the *theoretical* ACF and PACF of the autoregressive, moving average, and the mixed autoregressive and moving average processes.\n",
    "\n",
    "3. **Model checking**: Test whether the estimated model conforms to the specifications of a stationary univariate process. In particular, the residuals should be independent of each other and constant in mean and variance over time. If the estimation is inadequate, we have to return to step one and attempt to build a better model.\n",
    "\n",
    "\n",
    "* Let us recall the following table.\n",
    "\n",
    "|  Process      |          ACF         |          PACF        |\n",
    "|---------------|:--------------------:|:--------------------:|\n",
    "| **AR(p)**     |    tails off         | cutoff after lag $p$ |\n",
    "| **MA(q)**     | cutoff after lag $q$ |    tails off         |\n",
    "| **ARMA(p,q)** |    tails off         |    tails off         |\n",
    "\n",
    "\n",
    "* In general, the ACF of an autoregressive process is similar to the PACF of a moving average process, and vice versa.\n",
    "\n",
    "* Keep in mind that these are theoretical properties. In practice, the estimated sample ACF and PACF can come with large variances, deviating from the underlying theoretical behavior. As such, it is prudent to recognize that these are  but broad characteristics, and it is quite possible that several candidate models are narrowed down and will need to be investigaged further in the later stage of the modeling process.\n",
    "\n",
    "|  Process      |          ACF         |          PACF        |\n",
    "|---------------|:--------------------:|:--------------------:|\n",
    "| **ARIMA(p,d,0)**     |    tails off         | cutoff after lag $p$ |\n",
    "| **ARIMA(0,d,q)**     | cutoff after lag $q$ |   tails off         |\n",
    "| **ARIMA(p,d,q)** |   tails off         |   tails off         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(filename = 'ARIMA FLOW CHART.jpg', width = 200, height = 200 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section, we will fit ARIMA to BitCoin, Amazon and Apple high prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin High Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_ARIMA(BitCoin['High'], order=(4,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ARIMA_plot_ki(series = BitCoin['High'], order = (4,2,3), train_size_percent = 0.9, scale = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_BIC_HIQC(BitCoin['High'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon High Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_ARIMA(Amazon['High'], order = (1,1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ARIMA_plot_ki(series = Amazon['High'], order = (2,1,1), train_size_percent = 0.9, scale = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_BIC_HIQC(Amazon['High'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple High Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsplot(AAPL_df['High'], title = 'Apple High Price', lags = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(fit_ARIMA(AAPL_df['High'], order = (5,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ARIMA_plot_ki(series = AAPL_df['High'], order = (5,2,0), train_size_percent = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_BIC_HIQC(AAPL_df['High'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The 'residuals' in a time series are what is left over after fitting a model. More precisely, residual is the difference between true and predicted value. \n",
    "\n",
    "* For many (but not all) time series models, the **residuals** are equal to the difference between the observations and the corresponding fitted values: \n",
    "\n",
    "$$\\epsilon_t = X_t - \\hat{X_t}$$\n",
    "\n",
    "* Residuals are useful in checking whether a model has adequately captured the information in the data. \n",
    "\n",
    "* A good forecasting model will yield residuals with the following properties: \n",
    "\n",
    "\n",
    "1. $\\textbf{The residuals are uncorrelated}$. If there are correlations between residuals, then there is information left in the residuals which shoud be used in computing forecasts. This can be done through inspecting acf plot.\n",
    "\n",
    "2. $\\textbf{The residuals have zero mean}$. If the residuals have a mean other than zero, then the forecasts are biased. This can be done in various ways, say, histogram.\n",
    "\n",
    "3. $\\textbf{The residuals follow a normal distribution}.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# residual of Apple's stock prices\n",
    "\n",
    "model = ARIMA(AAPL_df['High'], order = (5,2,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "residual = model_fit.resid\n",
    "tsplot(residual, title = 'Residuals', lags = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To check normality, one can use Jarque-Bera test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether residuals follow a normal distribution\n",
    "from scipy import stats\n",
    "\n",
    "jb = stats.jarque_bera(residual)    \n",
    "print(\"Jarque-Bera Test Results: \")\n",
    "print(\"Test Statistic: %.4f\" % jb[0])\n",
    "print(\"p-value: %.10f\" % jb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For Jarque-Bera test, the null hypothesis is that skewness is zero and excess kurtosis is zero, that is, the data follows a normal distribution. Alternative hypothesis would be otherwise.\n",
    "\n",
    "* Since $p$-value is less than $0.05,$ we should reject null hypothesis. In other words, residuals are not normally distributed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
